# -*- coding: utf-8 -*-
"""Hackathon.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12GRHSWR92dDQjzGwEVwVJJoaqnrZ5o-z

OBTAINING ALL TWEETS FROM A USER
"""

import requests
import json
import pandas as pd
import tweepy

#pip install --upgrade tweepy  # needed v.4

# LA LLAVE
BEARER_TOKEN = "AAAAAAAAAAAAAAAAAAAAAF02cQEAAAAAAw4Ko%2BlvaP%2FEKo4jetBjHN%2BGEpY%3D8ot7Zeg7DytI7xLRXuZO23cSWSLBIAHPMKrw9b8jebi9j7nWsI"

"""#Extracción de data a partir del @username.
Basado en Tweepy v4.9.0
"""

input_user = 'mferna'

def extract_tweet_data(input_user):
    """
    Extracts data from a Twitter account.

    Parameters:

    Returns:
    pd.DataFrame
        A dataframe of the user tweets containing the language, time of creation,
        text, tweet id, number of retweets and number of likes.
    """
    # Authorize access
    client = tweepy.Client(BEARER_TOKEN)

    # Get user ID from username
    user_id = client.get_user(username=input_user).data.id

    # Get Tweets timeline (check all pages, max 100 tweets per page, max 32 pages)
    df_list = []
    df_len0 = []
    df_len = []
    for response in tweepy.Paginator(client.get_users_tweets, user_id,
                                    tweet_fields='created_at,lang,public_metrics',
                                    max_results=100, limit=32):
        page_df = pd.DataFrame.from_dict(response.data)
        df_len0.append(len(page_df))
        # Delete non-spanish tweets
        page_df = page_df.drop(page_df[page_df.lang !='es'].index)
        page_df = page_df.drop(['lang'], axis=1)
        df_len.append(len(page_df))
        # Organize columns
        retweet_count = []
        like_count = []
        for item in page_df['public_metrics'].tolist():
          retweet_count.append(item['retweet_count'])
          like_count.append(item['like_count'])
        page_df = page_df.drop(['public_metrics'], axis=1)
        page_df['retweet_count'] = retweet_count
        page_df['like_count'] = like_count
        df_list.append(page_df)
    es_tweets = round(sum(df_len)*100/sum(df_len0),1)
    print(f'Obtained {es_tweets}% tweets in spanish from total of {sum(df_len0)} tweets from user @{input_user}.')
    tweets_df = pd.concat(df_list, ignore_index=True)
    return tweets_df

"""OLD EXTRACTION CODE (only works for obtaining user info, and only 100 tweets max)\
Es una modificación de los ejemplos para obtener [info del user](https://github.com/twitterdev/Twitter-API-v2-sample-code/blob/main/User-Lookup/get_users_with_bearer_token.py) y [sus tweets](https://github.com/twitterdev/Twitter-API-v2-sample-code/blob/main/User-Tweet-Timeline/user_tweets.py)

"""

def create_url(username, twitter_object):
    if twitter_object == 'user':
      usernames = f'usernames={input_user}'
      user_fields = 'user.fields=description,created_at,protected,public_metrics,verified'
      url = f'https://api.twitter.com/2/users/by?{usernames}&{user_fields}'
    elif twitter_object == 'tweet':
      user_dict = get_json('user')
      user_id = user_dict['data'][0]['id']
      url = f'https://api.twitter.com/2/users/{user_id}/tweets?max_results=100'
    else:
      print('Error. Wrong Twitter Object.')
      return None
    return url


def get_params(twitter_object):
    if twitter_object == 'tweet':
      params = {"tweet.fields": "created_at,lang,public_metrics"}
    else:
      print('Error. Wrong Twitter Object.')
      return None
    return params


def bearer_oauth_user(r):
    r.headers["Authorization"] = f"Bearer {BEARER_TOKEN}"
    r.headers["User-Agent"] = "v2UserLookupPython"
    return r


def bearer_oauth_tweet(r):
    r.headers["Authorization"] = f"Bearer {BEARER_TOKEN}"
    r.headers["User-Agent"] = "v2UserTweetsPython"
    return r


def connect_to_endpoint(url, twitter_object):
    if twitter_object == 'user':
      response = requests.request("GET", url, auth=bearer_oauth_user,)
    elif twitter_object == 'tweet':
      params = get_params('tweet')
      response = requests.request("GET", url, auth=bearer_oauth_tweet,params=params)
    else:
        print('Error. Wrong Twitter Object.')
        return None
    if response.status_code != 200:
        raise Exception(f'Request returned an error: {response.status_code} {response.text}')
    return response.json()


def get_json(twitter_object):
    if twitter_object == 'user':
      url = create_url(input_user, 'user')
      json_response = connect_to_endpoint(url, 'user')
    elif twitter_object == 'tweet':
      url = create_url(input_user, 'tweet')
      json_response = connect_to_endpoint(url, 'tweet')
    else:
        print('Error. Wrong Twitter Object.')
        return None
    return json_response


def extract_user_data(username):  # MAIN FILE
    """
    Extracts data from a Twitter account.

    Parameters:

    Returns:
    dict
        A dict containing the releveant variables about the user
    """
    # Get user ID from username
    user_dict = get_json('user')
    #user_id = user_dict['data'][0]['id']

    # Get Tweets timeline
    #tweet_dict = get_json('tweet')
    #tweet_pd = pd.DataFrame.from_dict(tweet_dict['data'])
    return user_dict

"""#OUTPUTS:"""

extract_user_data(input_user)  ## Dict with user info

extract_tweet_data(input_user)  ## DataFrame with all tweets in spanish from user

"""#Procesamiento de data"""

# dummy input (after cleaning)
o_df = extract_tweet_data(input_user)
test_df = o_df.copy()
test_df.text = test_df.text.map(lambda t: t.split())
test_df

word = 'de'  # Test word

# Flatten text column
total_word_list = [word for word_list in o_df.text.tolist() for word in word_list]

word_count = total_word_list.count(word)  # 0TH VARIABLE
total_word_count = len(total_word_list)
freq = word_count/total_word_count  # FIRST VARIABLE


o_df['word_count'] = o_df.text.map(lambda t: t.count(word))
tweets_containing = o_df.word_count.astype(bool).sum()  #LIKE_COUNT_FLAG
like_count = o_df.like_count.sum()  # ARREGLAR
like_rate = like_count/tweets_containing  # SECOND


retweet_count = o_df.retweet_count.sum()  #ARREGLAR
retweet_rate = retweet_count/tweets_containing  # THIRD

# 4 and 5
popularity  = retweet_rate/freq
polemicity  = retweet_rate/like_rate

#BUSCAR POR BIGRAMAS Y TRIGRAMAS

print(f'\'{word}\' found {word_count} times.')
print(f'freq: {freq}.')
print(f'like_rate: {like_rate}.')
print(f'retweet_rate: {retweet_rate}.')
print(f'popularity: {popularity}.')
print(f'polemicity: {polemicity}.')
o_df

def variables(word, df):
    # Flatten text column
    total_word_list = [word for word_list in df.text.tolist() for word in word_list]

    word_count = total_word_list.count(word)
    total_word_count = len(total_word_list)
    freq = word_count/total_word_count

    df['word_count'] = df.text.map(lambda t: t.count(word))
    tweets_containing = df['word_count'].astype(bool).sum()
    df.drop(['word_count'], axis=1)
    like_count = df.like_count.sum()
    like_rate = like_count/tweets_containing

    retweet_count = df.retweet_count.sum()
    retweet_rate = retweet_count/tweets_containing

    popularity  = retweet_rate/freq
    polemicity  = retweet_rate/like_rate

    variables = (freq, like_rate, retweet_rate, popularity, polemicity)
    return variables, word_count

variables('de', test_df)

